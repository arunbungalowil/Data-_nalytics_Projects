{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "[Hacker News](https://news.ycombinator.com/) is a site started by the startup incubator [Y Combinator](https://www.ycombinator.com/), where user-submitted stories (known as \"posts\") receive votes and comments, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "###  What data will we be working with?\n",
    "\n",
    "In this project, we will work with a dataset of posts on Hacker News. The original [dataset](https://www.kaggle.com/datasets/hacker-news/hacker-news-posts) has almost 300,000 posts, but the dataset we will be working with is a [subset](https://app.dataquest.io/jupyter/edit/notebook/hacker_news.csv) of around 20,000 posts found by removing all posts that didn't receive any comments and then randomly sampling from the remaining posts in the original data.\n",
    "\n",
    "For this project, we're specifically interested in posts with titles that begin with either *Ask HN or Show HN*:\n",
    "\n",
    "Users submit **Ask HN** posts to ask the Hacker News community a specific question.\n",
    "Users submit **Show HN** posts to show the Hacker News community a project, product, or just something interesting.\n",
    "What is the purpose of this project?\n",
    "\n",
    "The questions we want to answer by the end of this project are:\n",
    "\n",
    "1. *Do Ask HN or Show HN receive more comments on average?*\n",
    "2. *Do posts created at a certain time receive more comments on average?*\n",
    "\n",
    "Below are descriptions of the columns:\n",
    "\n",
    "1. id: the unique identifier from Hacker News for the post\n",
    "2. title: the title of the post\n",
    "3. url: the URL that the posts links to, if the post has a URL\n",
    "4. num_points: the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "num_comments: the number of comments on the post\n",
    "5. author: the username of the person who submitted the post\n",
    "6. created_at: the date and time of the post's submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening & Reading the Dataset\n",
    "\n",
    "First lets open and read the data file (hacker_news.csv). First we will import reader from the CSV module, as this simplifies reading CSV files. Once we have opened and read the file, we will convert it to a list, assigned the variable hn (for Hacker News), and print the first five rows for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "hn = list(reader(opened_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "# Display the first five rows of hn.\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "# Displaying first row of data\n",
    "headers = hn[0]\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12'], ['10482257', 'Title II kills investment? Comcast and other ISPs are now spending more', 'http://arstechnica.com/business/2015/10/comcast-and-other-isps-boost-network-investment-despite-net-neutrality/', '53', '22', 'Deinos', '10/31/2015 9:48']]\n"
     ]
    }
   ],
   "source": [
    "# Removing the first row from hn.\n",
    "hn = hn[1:]\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts\n",
    "\n",
    "In *Ask HN or Show HN* posts, these are the first words that appear in the title of the post. We can therefore use the startswith string method to find these posts. As capitalisation matters when using the startswith method on strings, we will also want to use the lower method on the post titles, as this returns a lowercase version of the starting string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = list()\n",
    "show_posts = list()\n",
    "other_posts = list()\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    \n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in ask_posts: 1744\n",
      "Number of posts in show_posts: 1162\n",
      "Number of posts in other_posts: 17193\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of posts in ask_posts: {len(ask_posts)}')\n",
    "print(f'Number of posts in show_posts: {len(show_posts)}')\n",
    "print(f'Number of posts in other_posts: {len(other_posts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12296411',\n",
       "  'Ask HN: How to improve my personal website?',\n",
       "  '',\n",
       "  '2',\n",
       "  '6',\n",
       "  'ahmedbaracat',\n",
       "  '8/16/2016 9:55'],\n",
       " ['10610020',\n",
       "  'Ask HN: Am I the only one outraged by Twitter shutting down share counts?',\n",
       "  '',\n",
       "  '28',\n",
       "  '29',\n",
       "  'tkfx',\n",
       "  '11/22/2015 13:43'],\n",
       " ['11610310',\n",
       "  'Ask HN: Aby recent changes to CSS that broke mobile?',\n",
       "  '',\n",
       "  '1',\n",
       "  '1',\n",
       "  'polskibus',\n",
       "  '5/2/2016 10:14'],\n",
       " ['12210105',\n",
       "  'Ask HN: Looking for Employee #3 How do I do it?',\n",
       "  '',\n",
       "  '1',\n",
       "  '3',\n",
       "  'sph130',\n",
       "  '8/2/2016 14:20'],\n",
       " ['10394168',\n",
       "  'Ask HN: Someone offered to buy my browser extension from me. What now?',\n",
       "  '',\n",
       "  '28',\n",
       "  '17',\n",
       "  'roykolak',\n",
       "  '10/15/2015 16:38']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing first five rows of ask hn posts\n",
    "ask_posts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10627194',\n",
       "  'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform',\n",
       "  'https://iot.seeed.cc',\n",
       "  '26',\n",
       "  '22',\n",
       "  'kfihihc',\n",
       "  '11/25/2015 14:03'],\n",
       " ['10646440',\n",
       "  'Show HN: Something pointless I made',\n",
       "  'http://dn.ht/picklecat/',\n",
       "  '747',\n",
       "  '102',\n",
       "  'dhotson',\n",
       "  '11/29/2015 22:46'],\n",
       " ['11590768',\n",
       "  'Show HN: Shanhu.io, a programming playground powered by e8vm',\n",
       "  'https://shanhu.io',\n",
       "  '1',\n",
       "  '1',\n",
       "  'h8liu',\n",
       "  '4/28/2016 18:05'],\n",
       " ['12178806',\n",
       "  'Show HN: Webscope  Easy way for web developers to communicate with Clients',\n",
       "  'http://webscopeapp.com',\n",
       "  '3',\n",
       "  '3',\n",
       "  'fastbrick',\n",
       "  '7/28/2016 7:11'],\n",
       " ['10872799',\n",
       "  'Show HN: GeoScreenshot  Easily test Geo-IP based web pages',\n",
       "  'https://www.geoscreenshot.com/',\n",
       "  '1',\n",
       "  '9',\n",
       "  'kpsychwave',\n",
       "  '1/9/2016 20:45']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing first five rows of show hn posts\n",
    "show_posts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "# Find the total number of comments in ask posts, and assign it to total_ask_comments.?\n",
    "\n",
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    comments = int(row[4])\n",
    "    total_ask_comments += comments\n",
    "    \n",
    "# average number of comments on ask posts\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "# Find the total number of comments in show posts, and assign it to total_show_comments.?\n",
    "\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    comments = int(row[4])\n",
    "    total_show_comments += comments\n",
    "# average number of comments on show posts\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the average number of comments on a Ask HN post is ~14, whereas the average number of comments on a Show HN post is ~10. We can therefore conclude that **Ask HN posts receive more comments than Show HN posts on average**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Number of Ask Posts and Comments by Hour Created\n",
    "\n",
    "we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the number of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['8/16/2016 9:55', 6], ['11/22/2015 13:43', 29], ['5/2/2016 10:14', 1], ['8/2/2016 14:20', 3], ['10/15/2015 16:38', 17]]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over ask_posts, and append to result_list a list with two elements:\n",
    "# The first element should be the column created_at, index position 6.\n",
    "# The second element should be the number of comments of the post, index position 4.\n",
    "# convert the value to an integer.\n",
    "\n",
    "import datetime as dt\n",
    "result_list = list()\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6],int(row[4])])\n",
    "\n",
    "print(result_list[:5])\n",
    "\n",
    "    \n",
    "# results_list is now a list of list, where each row\n",
    "# represents an Ask HN post, with the first element\n",
    "# the time (as a string currently) at which the post\n",
    "# was created, and the second element, the number of \n",
    "# comments on the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_hour = dict()\n",
    "comments_by_hour = dict()\n",
    "\n",
    "for row in result_list:\n",
    "    date_obj = dt.datetime.strptime(row[0], '%m/%d/%Y %H:%M')\n",
    "    # we can see this is the format used in our data\n",
    "    # by looking at the rows we printed earlier -\n",
    "    # at the top of this code box, I have re-printed an \n",
    "    # example which makes it clear that the month comes\n",
    "    # before the day\n",
    "    # print(date_obj)\n",
    "    hour = date_obj.strftime('%H')\n",
    "    # print(hour)\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = int(row[1])\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += int(row[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. counts_by_hour: contains the number of ask posts created during each hour of the day.\n",
    "2. comments_by_hour: contains the corresponding number of comments ask posts created at each hour received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n"
     ]
    }
   ],
   "source": [
    "print(counts_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN Posts by Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.58], ['13', 14.74], ['10', 13.44], ['14', 13.23], ['16', 16.8], ['23', 7.99], ['12', 9.41], ['17', 11.46], ['15', 38.59], ['21', 16.01], ['20', 21.52], ['02', 23.81], ['18', 13.2], ['03', 7.8], ['05', 10.09], ['19', 10.8], ['01', 11.38], ['22', 6.75], ['08', 10.25], ['04', 7.17], ['00', 8.13], ['06', 9.02], ['07', 7.85], ['11', 11.05]]\n"
     ]
    }
   ],
   "source": [
    "avg_comments = list()\n",
    "for key in counts_by_hour:\n",
    "    avg = round((comments_by_hour[key] / counts_by_hour[key]) ,2)\n",
    "    avg_comments.append([key,avg])\n",
    "print(avg_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this format makes it difficult to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.58, '09'], [14.74, '13'], [13.44, '10'], [13.23, '14'], [16.8, '16'], [7.99, '23'], [9.41, '12'], [11.46, '17'], [38.59, '15'], [16.01, '21'], [21.52, '20'], [23.81, '02'], [13.2, '18'], [7.8, '03'], [10.09, '05'], [10.8, '19'], [11.38, '01'], [6.75, '22'], [10.25, '08'], [7.17, '04'], [8.13, '00'], [9.02, '06'], [7.85, '07'], [11.05, '11']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = list()\n",
    "for row in avg_comments:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "# average number of comments will be the first element(0 index position)\n",
    "# hour will be the seconf element(1 index position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.59, '15'], [23.81, '02'], [21.52, '20'], [16.8, '16'], [16.01, '21'], [14.74, '13'], [13.44, '10'], [13.23, '14'], [13.2, '18'], [11.46, '17'], [11.38, '01'], [11.05, '11'], [10.8, '19'], [10.25, '08'], [10.09, '05'], [9.41, '12'], [9.02, '06'], [8.13, '00'], [7.99, '23'], [7.85, '07'], [7.8, '03'], [7.17, '04'], [6.75, '22'], [5.58, '09']]\n"
     ]
    }
   ],
   "source": [
    "# sorting values based on average comments, descending order\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print(sorted_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00 38.59 average comments per post\n",
      "02:00 23.81 average comments per post\n",
      "20:00 21.52 average comments per post\n",
      "16:00 16.8 average comments per post\n",
      "21:00 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "for row in sorted_swap[:5]:\n",
    "    time_obj = dt.datetime.strptime(row[1], '%H')\n",
    "    time = time_obj.strftime('%H:%M')\n",
    "    print('{} {} average comments per post'.format(time,row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, we can conclude that posts created at a certain time do receive more comments, and more specifically that the hour that receives the most comments per post on average, is 15:00, with an average of around 38 comments per post. 02:00 has the second highest number of average comments per post, at around 24 comments - but this is quite a lot less than 15:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
